nohup: ignoring input
[36m[[[airflow-3831]]][0m
[[[ Node ]]]
if len(path_components) < 2:
    raise Exception('Invalid Google Cloud Storage (GCS) object path: {}.'.format(file_name))
[32mPASSED![0m
Time :  43.03 seconds

[36m[[[airflow-4674]]][0m
[33mERROR...[0m
  File "/home/wonseok/pyfix/my_tool/test_main.py", line 317, in run
    works.work()
  File "/home/wonseok/pyfix/my_tool/work.py", line 1233, in work
    neg_file_node = deepcopy(self.files[neg_filename])
'/home/wonseok/benchmark/airflow-4674/tests/test_configuration.py'
Time :  0.03 seconds

[36m[[[airflow-5686]]][0m
[[[ Node ]]]
if self.http_conn_id:
    conn = self.get_connection(self.http_conn_id)
    if conn.host and '://' in conn.host:
        self.base_url = conn.host
    else:
        schema = conn.schema if conn.schema else 'http'
        self.base_url = schema + '://' + ('' if isinstance(conn.host, type(None)) else conn.host)
    if conn.port:
        self.base_url = self.base_url + ':' + str(conn.port)
    if conn.login:
        session.auth = (conn.login, conn.password)
    if conn.extra:
        try:
            session.headers.update(conn.extra_dejson)
        except TypeError:
            self.log.warn('Connection to %s has invalid extra field.', conn.host)
[32mPASSED![0m
Time :  11.81 seconds

[36m[[[airflow-6036]]][0m
[31mFAILED...[0m
Time :  0.01 seconds

[36m[[[airflow-8151]]][0m
[31mFAILED...[0m
Time :  0.0 seconds

[36m[[[airflow-14513]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
[[[ Node ]]]
while True:
    logs = self.read_pod_logs(pod, timestamps=True, since_seconds=read_logs_since_sec)
    for line in logs:
        (timestamp, message) = self.parse_log_line(line.decode('utf-8'))
        last_log_time = pendulum.parse(timestamp)
        self.log.info(message)
    time.sleep(1)
    if not self.base_container_is_running(pod):
        break
    self.log.warning('Pod %s log read interrupted', pod.metadata.name)
    if isinstance(last_log_time, type(None)):
        continue
    delta = pendulum.now() - last_log_time
    read_logs_since_sec = math.ceil(delta.total_seconds())
[32mPASSED![0m
Time :  153.88 seconds

[36m[[[airflow-14686]]][0m
[31mFAILED...[0m
Time :  0.01 seconds

[36m[[[airflow-15395]]][0m
[31mFAILED...[0m
Time :  0.03 seconds

PASSED :  3 / 8
[36m[[[beets-3360]]][0m
[[[ Node ]]]
def uri(self, path):
    if not isinstance(path, bytes):
        return PurePosixPath(path).as_uri()
[32mPASSED![0m
Time :  3.33 seconds

PASSED :  1 / 1
PASSED :  0 / 0
[36m[[[core-1972]]][0m
[[[ Node ]]]
check = condition.from_config(action)(self.hass, variables)
[32mPASSED![0m
Time :  2.24 seconds

[36m[[[core-8065]]][0m
[[[ Node ]]]
ids = sorted(self.entities, key=lambda x: x if isinstance(self.entities[x].name, type(None)) else self.entities[x].name)
[32mPASSED![0m
Time :  14.22 seconds

[36m[[[core-20233]]][0m
[[[ Node ]]]
try:
    variables['value_json'] = json.loads(value)
except ValueError:
    pass
except TypeError:
    pass
[32mPASSED![0m
Time :  3.88 seconds

[36m[[[core-21734]]][0m
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  decimal.Decimal
None Type Casting Other Type
Type :  datetime.timedelta
[31mFAILED...[0m
Time :  359.12 seconds

[36m[[[core-29829]]][0m
[[[ Node ]]]
async def async_added_to_hass(self):
    """Run when entity about to be added to hass."""
    await super().async_added_to_hass()
    if self._current_value is not None:
        return
    state = await self.async_get_last_state()
    value = state and state.state
    if isinstance(self._minimum, type(None)):
        self._current_value = value
    elif value is not None and self._minimum <= len(value) <= self._maximum:
        self._current_value = value
[32mPASSED![0m
Time :  305.77 seconds

[36m[[[core-32222]]][0m
[[[ Node ]]]
since_last_seen = dt_util.utcnow() - dt_util.utc_from_timestamp(float(0 if isinstance(self.client.last_seen, type(None)) else self.client.last_seen))
[32mPASSED![0m
Time :  8.38 seconds

[36m[[[core-32318]]][0m
[31mFAILED...[0m
Time :  0.02 seconds

[36m[[[core-38605]]][0m
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
[31mFAILED...[0m
Time :  93.14 seconds

[36m[[[core-40034]]][0m
[[[ Node ]]]
while to_process:
    config = to_process.popleft()
    import homeassistant
    if isinstance(config, homeassistant.helpers.template.Template):
        continue
    condition = config[CONF_CONDITION]
    if condition in ('and', 'not', 'or'):
        to_process.extend(config['conditions'])
        continue
    entity_ids = config.get(CONF_ENTITY_ID)
    if isinstance(entity_ids, str):
        entity_ids = [entity_ids]
    if entity_ids is not None:
        referenced.update(entity_ids)
[[[ Node ]]]
while to_process:
    config = to_process.popleft()
    import homeassistant
    if isinstance(config, homeassistant.helpers.template.Template):
        continue
    condition = config[CONF_CONDITION]
    if condition in ('and', 'not', 'or'):
        to_process.extend(config['conditions'])
        continue
    if condition != 'device':
        continue
    device_id = config.get(CONF_DEVICE_ID)
    if device_id is not None:
        referenced.add(device_id)
[32mPASSED![0m
Time :  16.91 seconds

PASSED :  6 / 9
[36m[[[luigi-1836]]][0m
[[[ Node ]]]
if fd == proc.stdout.fileno():
    line = proc.stdout.readline().decode('utf8')
    import _io
    if not isinstance(temp_stdout, _io.BufferedRandom):
        temp_stdout.write(line)
[32mPASSED![0m
Time :  1.57 seconds

PASSED :  1 / 1
[36m[[[numpy-9999]]][0m
[[[ Node ]]]
def in1d(ar1, ar2, assume_unique=False, invert=False):
    """
    Test whether each element of a 1-D array is also present in a second array.

    Returns a boolean array the same length as `ar1` that is True
    where an element of `ar1` is in `ar2` and False otherwise.

    We recommend using :func:`isin` instead of `in1d` for new code.

    Parameters
    ----------
    ar1 : (M,) array_like
        Input array.
    ar2 : array_like
        The values against which to test each value of `ar1`.
    assume_unique : bool, optional
        If True, the input arrays are both assumed to be unique, which
        can speed up the calculation.  Default is False.
    invert : bool, optional
        If True, the values in the returned array are inverted (that is,
        False where an element of `ar1` is in `ar2` and True otherwise).
        Default is False. ``np.in1d(a, b, invert=True)`` is equivalent
        to (but is faster than) ``np.invert(in1d(a, b))``.

        .. versionadded:: 1.8.0

    Returns
    -------
    in1d : (M,) ndarray, bool
        The values `ar1[in1d]` are in `ar2`.

    See Also
    --------
    isin                  : Version of this function that preserves the
                            shape of ar1.
    numpy.lib.arraysetops : Module with a number of other functions for
                            performing set operations on arrays.

    Notes
    -----
    `in1d` can be considered as an element-wise function version of the
    python keyword `in`, for 1-D sequences. ``in1d(a, b)`` is roughly
    equivalent to ``np.array([item in b for item in a])``.
    However, this idea fails if `ar2` is a set, or similar (non-sequence)
    container:  As ``ar2`` is converted to an array, in those cases
    ``asarray(ar2)`` is an object array rather than the expected array of
    contained values.

    .. versionadded:: 1.4.0

    Examples
    --------
    >>> test = np.array([0, 1, 2, 5, 0])
    >>> states = [0, 2]
    >>> mask = np.in1d(test, states)
    >>> mask
    array([ True, False,  True, False,  True], dtype=bool)
    >>> test[mask]
    array([0, 2, 0])
    >>> mask = np.in1d(test, states, invert=True)
    >>> mask
    array([False,  True, False,  True, False], dtype=bool)
    >>> test[mask]
    array([1, 5])
    """
    ar1 = np.asarray(ar1).ravel()
    ar2 = np.asarray(ar2).ravel()
    if len(ar2) < 10 * len(ar1) ** 0.145:
        if invert:
            mask = np.ones(len(ar1), dtype=bool)
            for a in ar2:
                mask &= ar1 != a
        else:
            mask = np.zeros(len(ar1), dtype=bool)
            for a in ar2:
                mask |= ar1 == a
        return mask
    if not assume_unique:
        (ar1, rev_idx) = np.unique(ar1, return_inverse=True)
        import numpy
        import numpy
        if isinstance(ar2, numpy.ndarray) and ar2.dtype.type is numpy.object_:
            return mask
        elif isinstance(ar2, numpy.ndarray) and ar2.dtype.type is numpy.void:
            return mask
        ar2 = np.unique(ar2)
    ar = np.concatenate((ar1, ar2))
    import numpy
    if not (isinstance(ar, numpy.ndarray) and numpy.issubdtype(ar.dtype, numpy.number)):
        ar = ar.astype(numpy.number)
    order = ar.argsort(kind='mergesort')
    sar = ar[order]
    if invert:
        bool_ar = sar[1:] != sar[:-1]
    else:
        bool_ar = sar[1:] == sar[:-1]
    flag = np.concatenate((bool_ar, [invert]))
    ret = np.empty(ar.shape, dtype=bool)
    ret[order] = flag
    if assume_unique:
        return ret[:len(ar1)]
    else:
        return ret[rev_idx]
[32mPASSED![0m
Time :  4.31 seconds

[36m[[[numpy-10473]]][0m
[[[ Node ]]]
for k in range(0, m - n + 1):
    d = scale * r[k]
    q[k] = d
    import numpy
    if not (numpy.issubdtype(r.dtype, numpy.complex)):
        r = r.astype(numpy.complex)
    r[k:k + n + 1] -= d * v
[32mPASSED![0m
Time :  5.0 seconds

[36m[[[numpy-19094]]][0m
[[[ Node ]]]
if hasattr(i, '__parameters__'):
    import typing
    if isinstance(i, typing._GenericAlias):
        continue
    value = i[next(parameters)]
else:
    value = i
[32mPASSED![0m
Time :  4.1 seconds

PASSED :  3 / 3
[36m[[[pandas-15941]]][0m
[[[ Node ]]]
def is_string_dtype(arr_or_dtype):
    if isinstance(arr_or_dtype, type(None)):
        return False
    dtype = _get_dtype(arr_or_dtype)
    return dtype.kind in ('O', 'S', 'U') and (not is_period_dtype(dtype))
[[[ Node ]]]
def is_timedelta64_ns_dtype(arr_or_dtype):
    if isinstance(arr_or_dtype, type(None)):
        return False
    tipo = _get_dtype(arr_or_dtype)
    return tipo == _TD_DTYPE
[[[ Node ]]]
def is_string_like_dtype(arr_or_dtype):
    if isinstance(arr_or_dtype, type(None)):
        return False
    dtype = _get_dtype(arr_or_dtype)
    return dtype.kind in ('S', 'U')
[32mPASSED![0m
Time :  11.43 seconds

[36m[[[pandas-17430]]][0m
[31mFAILED...[0m
Time :  299.63 seconds

[36m[[[pandas-17609]]][0m
[[[ Node ]]]
defaults = ('',) * n_wo_defaults + tuple(spec.defaults)
[32mPASSED![0m
Time :  4.74 seconds

[36m[[[pandas-18831]]][0m
None Type Casting Other Type
Type :  pandas.core.series.Series
None Type Casting Other Type
Type :  pandas._libs.tslibs.timedeltas.Timedelta
None Type Casting Other Type
Type :  datetime.timedelta
None Type Casting Other Type
Type :  numpy.timedelta64
None Type Casting Other Type
Type :  function
[31mFAILED...[0m
Time :  1222.81 seconds

[36m[[[pandas-18849]]][0m
[33mERROR...[0m
  File "/home/wonseok/pyfix/my_tool/test_main.py", line 317, in run
    works.work()
  File "/home/wonseok/pyfix/my_tool/work.py", line 1233, in work
    neg_file_node = deepcopy(self.files[neg_filename])
'/home/wonseok/benchmark/pandas-18849/pandas/tests/indexes/datetimes/test_arithmetic.py'
Time :  14.92 seconds

[36m[[[pandas-19013]]][0m
Timeout!
Time :  3600.06 seconds

[36m[[[pandas-19276]]][0m
[[[ Node ]]]
def _assert_tzawareness_compat(self, other):
    import pandas
    if isinstance(other, pandas._libs.tslibs.nattype.NaTType):
        return None
    other_tz = getattr(other, 'tzinfo', None)
    if is_datetime64tz_dtype(other):
        other_tz = other.dtype.tz
    if self.tz is None:
        if other_tz is not None:
            raise TypeError('Cannot compare tz-naive and tz-aware datetime-like objects.')
    elif other_tz is None:
        raise TypeError('Cannot compare tz-naive and tz-aware datetime-like objects')
[32mPASSED![0m
Time :  10.73 seconds

[36m[[[pandas-20938]]][0m
/home/wonseok/benchmark/pandas-20938/pandas/tests/io/test_excel.py not exists
/home/wonseok/benchmark/pandas-20938/pandas/tests/io/test_excel.py not exists
[31mFAILED...[0m
Time :  7.19 seconds

[36m[[[pandas-20968]]][0m
[[[ Node ]]]
def boxplot_frame_groupby(grouped, subplots=True, column=None, fontsize=None, rot=0, grid=True, ax=None, figsize=None, layout=None, sharey=True, sharex=False, **kwds):
    """
    Make box plots from DataFrameGroupBy data.

    Parameters
    ----------
    grouped : Grouped DataFrame
    subplots :
        * ``False`` - no subplots will be used
        * ``True`` - create a subplot for each group
    column : column name or list of names, or vector
        Can be any valid input to groupby
    fontsize : int or string
    rot : label rotation angle
    grid : Setting this to True will show the grid
    ax : Matplotlib axis object, default None
    figsize : A tuple (width, height) in inches
    layout : tuple (optional)
        (rows, columns) for the layout of the plot
    `**kwds` : Keyword Arguments
        All other plotting keyword arguments to be passed to
        matplotlib's boxplot function

    Returns
    -------
    dict of key/value = group key/DataFrame.boxplot return value
    or DataFrame.boxplot return value in case subplots=figures=False

    Examples
    --------
    >>> import pandas
    >>> import numpy as np
    >>> import itertools
    >>>
    >>> tuples = [t for t in itertools.product(range(1000), range(4))]
    >>> index = pandas.MultiIndex.from_tuples(tuples, names=['lvl0', 'lvl1'])
    >>> data = np.random.randn(len(index),4)
    >>> df = pandas.DataFrame(data, columns=list('ABCD'), index=index)
    >>>
    >>> grouped = df.groupby(level='lvl1')
    >>> boxplot_frame_groupby(grouped)
    >>>
    >>> grouped = df.unstack(level='lvl1').groupby(level=0, axis=1)
    >>> boxplot_frame_groupby(grouped, subplots=False)
    """
    _raise_if_no_mpl()
    _converter._WARN = False
    if subplots is True:
        naxes = len(grouped)
        (fig, axes) = _subplots(naxes=naxes, squeeze=False, ax=ax, sharex=sharex, sharey=sharey, figsize=figsize, layout=layout)
        axes = _flatten(axes)
        from pandas.core.series import Series
        ret = Series()
        for ((key, group), ax) in zip(grouped, axes):
            d = group.boxplot(ax=ax, column=column, fontsize=fontsize, rot=rot, grid=grid, **kwds)
            ax.set_title(pprint_thing(key))
            ret.loc[key] = d
        fig.subplots_adjust(bottom=0.15, top=0.9, left=0.1, right=0.9, wspace=0.2)
    else:
        from pandas.core.reshape.concat import concat
        (keys, frames) = zip(*grouped)
        if grouped.axis == 0:
            df = concat(frames, keys=keys, axis=1)
        elif len(frames) > 1:
            df = frames[0].join(frames[1:])
        else:
            df = frames[0]
        ret = df.boxplot(column=column, fontsize=fontsize, rot=rot, grid=grid, ax=ax, figsize=figsize, layout=layout, **kwds)
    return ret
[32mPASSED![0m
Time :  59.43 seconds

[36m[[[pandas-21540]]][0m
[[[ Node ]]]
result.rename(columns=lambda x: record_prefix + str(x), inplace=True)
[32mPASSED![0m
Time :  29.28 seconds

[36m[[[pandas-21590]]][0m
[[[ Node ]]]
if is_numeric_dtype(values) or is_timedelta64_dtype(values):
    arr = operator.neg(values)
else:
    import numpy
    if isinstance(values, numpy.ndarray) and values.dtype.type is numpy.object_:
        arr = operator.neg(values)
    else:
        raise TypeError('Unary negative expects numeric dtype, not {}'.format(values.dtype))
[[[ Node ]]]
if is_numeric_dtype(values) or is_timedelta64_dtype(values):
    arr = operator.pos(values)
else:
    import numpy
    if isinstance(values, numpy.ndarray) and values.dtype.type is numpy.object_:
        arr = operator.pos(values)
    else:
        raise TypeError('Unary plus expects numeric dtype, not {}'.format(values.dtype))
[32mPASSED![0m
Time :  402.89 seconds

[36m[[[pandas-22072]]][0m
[[[ Node ]]]
cat = Categorical(values, ordered=False)
[32mPASSED![0m
Time :  7.12 seconds

[36m[[[pandas-22198]]][0m
[[[ Node ]]]
result[(locs == 0) & (where.values < self.values[first])] = -1
[32mPASSED![0m
Time :  104.37 seconds

[36m[[[pandas-22378]]][0m
[[[ Node ]]]
if is_categorical_dtype(left):
    raise TypeError('{typ} cannot perform the operation {op}'.format(typ=type(left).__name__, op=str_rep))
elif not isinstance(right, str):
    if is_extension_array_dtype(left) or is_extension_array_dtype(right):
        return dispatch_to_extension_op(op, left, right)
    elif is_datetime64_dtype(left) or is_datetime64tz_dtype(left):
        result = dispatch_to_index_op(op, left, right, pd.DatetimeIndex)
        return construct_result(left, result, index=left.index, name=res_name, dtype=result.dtype)
    elif is_timedelta64_dtype(left):
        result = dispatch_to_index_op(op, left, right, pd.TimedeltaIndex)
        return construct_result(left, result, index=left.index, name=res_name, dtype=result.dtype)
[32mPASSED![0m
Time :  746.33 seconds

[36m[[[pandas-22804]]][0m
[[[ Node ]]]
def _recursive_extract(data, path, seen_meta, level=0):
    if isinstance(data, dict):
        data = [data]
    if len(path) > 1:
        for obj in data:
            for (val, key) in zip(meta, meta_keys):
                if level + 1 == len(val):
                    seen_meta[key] = _pull_field(obj, val[-1])
            _recursive_extract(obj[path[0]], path[1:], seen_meta, level=level + 1)
    else:
        for obj in data:
            recs = _pull_field(obj, path[0])
            lengths.append(len(recs))
            for (val, key) in zip(meta, meta_keys):
                if level + 1 > len(val):
                    meta_val = seen_meta[key]
                else:
                    try:
                        meta_val = _pull_field(obj, val[level:])
                    except KeyError as e:
                        if errors == 'ignore':
                            meta_val = np.nan
                        else:
                            raise KeyError("Try running with errors='ignore' as key {err} is not always present".format(err=e))
                meta_vals[key].append(meta_val)
            records.extend(recs)
[32mPASSED![0m
Time :  31.48 seconds

[36m[[[pandas-24572]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
Timeout!
Time :  3600.04 seconds

[36m[[[pandas-25533]]][0m
[[[ Node ]]]
try:
    if takeable:
        self._values[label] = value
    else:
        self.index._engine.set_value(self._values, label, value)
except KeyError:
    self.loc[label] = value
except TypeError:
    self.loc[label] = value
[32mPASSED![0m
Time :  9.02 seconds

[36m[[[pandas-25759]]][0m
[[[ Node ]]]
if is_list_like_indexer(key):
    arr = np.array(key)
    len_axis = len(self.obj._get_axis(axis))
    import numpy
    if not (isinstance(arr, numpy.ndarray) and numpy.issubdtype(arr.dtype, numpy.number)):
        raise IndexError('.iloc requires numeric indexers, got')
    if len(arr) and (arr.max() >= len_axis or arr.min() < -len_axis):
        raise IndexError('positional indexers are out-of-bounds')
else:
    raise ValueError('Can only index by location with a [{types}]'.format(types=self._valid_types))
[32mPASSED![0m
Time :  3087.85 seconds

[36m[[[pandas-26324]]][0m
[31mFAILED...[0m
Time :  0.75 seconds

[36m[[[pandas-26765]]][0m
[[[ Node ]]]
try:
    loc = cat.categories.get_loc(key)
except KeyError:
    return False
except TypeError:
    return False
[32mPASSED![0m
Time :  20.86 seconds

[36m[[[pandas-28251]]][0m
[[[ Node ]]]
if is_timedelta:
    res = arr[res_indexer]
    lag = arr[lag_indexer]
    mask = (arr[res_indexer] == na) | (arr[lag_indexer] == na)
    if mask.any():
        res = res.copy()
        res[mask] = 0
        lag = lag.copy()
        lag[mask] = 0
    result = res - lag
    result[mask] = na
    out_arr[res_indexer] = result
else:
    import numpy
    if isinstance(arr, numpy.ndarray) and arr.dtype.type is numpy.bool_:
        out_arr[res_indexer] = arr[res_indexer] ^ arr[lag_indexer]
    else:
        out_arr[res_indexer] = arr[res_indexer] - arr[lag_indexer]
[32mPASSED![0m
Time :  319.98 seconds

[36m[[[pandas-28412]]][0m
[[[ Node ]]]
to_concat = [self] + list(to_append)
[32mPASSED![0m
Time :  8.92 seconds

[36m[[[pandas-29103]]][0m
[[[ Node ]]]
def maybe_downcast_to_dtype(result, dtype):
    """ try to cast to the specified dtype (e.g. convert back to bool/int
    or could be an astype of float64->float32
    """
    do_round = False
    if is_scalar(result):
        return result
    elif isinstance(result, ABCDataFrame):
        return result
    if isinstance(dtype, str):
        if dtype == 'infer':
            inferred_type = lib.infer_dtype(ensure_object(result.ravel()), skipna=False)
            if inferred_type == 'boolean':
                dtype = 'bool'
            elif inferred_type == 'integer':
                dtype = 'int64'
            elif inferred_type == 'datetime64':
                dtype = 'datetime64[ns]'
            elif inferred_type == 'timedelta64':
                dtype = 'timedelta64[ns]'
            elif inferred_type == 'floating':
                dtype = 'int64'
                if issubclass(result.dtype.type, np.number):
                    do_round = True
            else:
                dtype = 'object'
        dtype = np.dtype(dtype)
    import numpy
    if isinstance(result, numpy.ndarray) and result.dtype.type is numpy.object_:
        return result
    converted = maybe_downcast_numeric(result, dtype, do_round)
    if converted is not result:
        return converted
    if dtype.kind in ['M', 'm'] and result.dtype.kind in ['i', 'f']:
        if hasattr(dtype, 'tz'):
            if dtype.tz:
                from pandas import to_datetime
                result = to_datetime(result).tz_localize('utc')
                result = result.tz_convert(dtype.tz)
        else:
            result = result.astype(dtype)
    elif dtype.type is Period:
        from pandas.core.arrays import PeriodArray
        try:
            return PeriodArray(result, freq=dtype.freq)
        except TypeError:
            pass
    return result
[32mPASSED![0m
Time :  5.16 seconds

[36m[[[pandas-30225]]][0m
[31mFAILED...[0m
Time :  1586.16 seconds

[36m[[[pandas-30532]]][0m
None Type Casting Other Type
Type :  None
[31mFAILED...[0m
Time :  237.13 seconds

[36m[[[pandas-31477]]][0m
[[[ Node ]]]
try:
    return self._cython_agg_general(how=alias, alt=npfunc, numeric_only=numeric_only, min_count=min_count)
except DataError:
    pass
except NotImplementedError as err:
    if 'function is not implemented for this dtype' in str(err):
        pass
    else:
        raise
except TypeError:
    pass
[32mPASSED![0m
Time :  9.94 seconds

[36m[[[pandas-31905]]][0m
[31mFAILED...[0m
Time :  356.3 seconds

[36m[[[pandas-32223]]][0m
[[[ Node ]]]
try:
    result = type(block.values)._from_sequence(result.ravel(), dtype=block.values.dtype)
except ValueError:
    result = result.reshape(1, -1)
except TypeError:
    result = result.reshape(1, -1)
[32mPASSED![0m
Time :  66.62 seconds

[36m[[[pandas-32953]]][0m
[[[ Node ]]]
if isinstance(objs, dict) or isinstance(objs, abc.Mapping):
    if keys is None:
        keys = list(objs.keys())
    objs = [objs[k] for k in keys]
else:
    objs = list(objs)
[32mPASSED![0m
Time :  6.95 seconds

[36m[[[pandas-33373]]][0m
[[[ Node ]]]
try:
    new_data = to_datetime(new_data, errors='raise', unit=date_unit)
except (ValueError, OverflowError):
    continue
except TypeError:
    continue
[32mPASSED![0m
Time :  15.7 seconds

[36m[[[pandas-33663]]][0m
None Type Casting Other Type
Type :  pandas.core.reshape.reshape._Unstacker
None Type Casting Other Type
Type :  pandas.core.reshape.reshape._Unstacker
None Type Casting Other Type
Type :  pandas.core.reshape.reshape._Unstacker
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
[31mFAILED...[0m
Time :  2384.6 seconds

[36m[[[pandas-34220]]][0m
[31mFAILED...[0m
Time :  503.06 seconds

[36m[[[pandas-36950]]][0m
[[[ Node ]]]
(result, how) = self._aggregate(func, axis, *args, **kwargs)
[32mPASSED![0m
Time :  6.67 seconds

[36m[[[pandas-37096]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
Timeout!
Time :  3600.07 seconds

[36m[[[pandas-37547]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
None Type Casting Other Type
Type :  pandas.core.indexes.base.Index
Timeout!
Time :  3602.29 seconds

[36m[[[pandas-37736]]][0m
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  re.Pattern
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  re.Pattern
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  numbers.Integral
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
None Type Casting Other Type
Type :  pathlib.PosixPath
[31mFAILED...[0m
Time :  1451.57 seconds

[36m[[[pandas-38220]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
None Type Casting Other Type
Type :  numpy.ndarray<<object_>>
Timeout!
Time :  3604.95 seconds

[36m[[[pandas-38431]]][0m
[[[ Node ]]]
j = i if isinstance(self.index_col, type(None)) else self.index_col[i]
[32mPASSED![0m
Time :  20.59 seconds

[36m[[[pandas-39028-1]]][0m
None Type Casting Other Type
Type :  pandas.core.frame.DataFrame
[31mFAILED...[0m
Time :  1595.08 seconds

[36m[[[pandas-39028-2]]][0m
Timeout!
Time :  3600.24 seconds

[36m[[[pandas-39095]]][0m
[[[ Node ]]]
if tolerance is not None and len(self):
    import numpy
    if not (isinstance(tolerance, numpy.ndarray) and numpy.issubdtype(tolerance.dtype, numpy.int)):
        return indexer
    indexer = self._filter_indexer_tolerance(target_values, indexer, tolerance)
[32mPASSED![0m
Time :  1235.45 seconds

[36m[[[pandas-40180]]][0m
[31mFAILED...[0m
Time :  0.99 seconds

[36m[[[pandas-41155]]][0m
None Type Casting Other Type
Type :  None
Timeout!
Time :  3600.08 seconds

[36m[[[pandas-41406]]][0m
[[[ Node ]]]
try:
    res = idx._get_string_slice(key)
    warnings.warn('Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.', FutureWarning, stacklevel=3)
    return res
except (KeyError, ValueError, NotImplementedError):
    return None
except TypeError:
    return None
[32mPASSED![0m
Time :  6.08 seconds

[36m[[[pandas-41915]]][0m
[33mERROR...[0m
  File "/home/wonseok/pyfix/my_tool/test_main.py", line 317, in run
    works.work()
  File "/home/wonseok/pyfix/my_tool/work.py", line 1240, in work
    ast_list = call_chain.do_call_chain()
  File "/home/wonseok/pyfix/my_tool/type_analysis/call_chain.py", line 198, in do_call_chain
    neg_file_node = deepcopy(self.files[neg_filename])
'/home/wonseok/benchmark/pandas-41915/pandas/tests/indexes/multi/test_setops.py'
Time :  3.31 seconds

PASSED :  24 / 45
[36m[[[rasa-8704]]][0m
[31mFAILED...[0m
Time :  0.0 seconds

PASSED :  0 / 1
[36m[[[requests-3179]]][0m
[[[ Node ]]]
if self.content and (not self.encoding and len(self.content) > 3):
    encoding = guess_json_utf(self.content)
    if encoding is not None:
        try:
            return complexjson.loads(self.content.decode(encoding), **kwargs)
        except UnicodeDecodeError:
            pass
[32mPASSED![0m
Time :  36.9 seconds

[36m[[[requests-3368]]][0m
[[[ Node ]]]
if self._content_consumed and isinstance(self._content, bool):
    raise StreamConsumedError()
elif chunk_size and (not isinstance(chunk_size, int)):
    raise TypeError('chunk_size must be an int, it is instead a %s.' % type(chunk_size))
[32mPASSED![0m
Time :  24.46 seconds

[36m[[[requests-3390]]][0m
None Type Casting Other Type
Type :  requests.models.Request
None Type Casting Other Type
Type :  requests.models.Request
None Type Casting Other Type
Type :  requests.models.Request
None Type Casting Other Type
Type :  requests.models.Request
None Type Casting Other Type
Type :  requests.models.Request
None Type Casting Other Type
Type :  requests.models.Request
[[[ Node ]]]
def check_header_validity(header):
    """Verifies that header value doesn't contain leading whitespace or
    return characters. This prevents unintended header injection.

    :param header: tuple, in the format (name, value).
    """
    (name, value) = header
    if isinstance(value, bytes):
        pat = _CLEAN_HEADER_REGEX_BYTE
    else:
        pat = _CLEAN_HEADER_REGEX_STR
    if not (isinstance(value, str) or isinstance(value, bytes)):
        raise InvalidHeader
    if not pat.match(value):
        raise InvalidHeader('Invalid return character or leading space in header: %s' % name)
[32mPASSED![0m
Time :  608.76 seconds

[36m[[[requests-4723]]][0m
[[[ Node ]]]
def should_bypass_proxies(url, no_proxy):
    """
    Returns whether we should bypass proxies or not.

    :rtype: bool
    """
    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())
    no_proxy_arg = no_proxy
    if no_proxy is None:
        no_proxy = get_proxy('no_proxy')
    parsed = urlparse(url)
    if isinstance(parsed.hostname, type(None)):
        return True
    if no_proxy:
        no_proxy = (host for host in no_proxy.replace(' ', '').split(',') if host)
        if is_ipv4_address(parsed.hostname):
            for proxy_ip in no_proxy:
                if is_valid_cidr(proxy_ip):
                    if address_in_network(parsed.hostname, proxy_ip):
                        return True
                elif parsed.hostname == proxy_ip:
                    return True
        else:
            host_with_port = parsed.hostname
            if parsed.port:
                host_with_port += ':{0}'.format(parsed.port)
            for host in no_proxy:
                if parsed.hostname.endswith(host) or host_with_port.endswith(host):
                    return True
    with set_environ('no_proxy', no_proxy_arg):
        try:
            bypass = proxy_bypass(parsed.hostname)
        except (TypeError, socket.gaierror):
            bypass = False
    if bypass:
        return True
    return False
[32mPASSED![0m
Time :  14.9 seconds

PASSED :  4 / 4
[36m[[[rich-919]]][0m
[31mFAILED...[0m
Time :  0.0 seconds

PASSED :  0 / 1
[36m[[[salt-33908]]][0m
[[[ Node ]]]
for key in set(new or {}).union(old or {}):
    if isinstance(new, type(None)):
        new = {}
    if key not in old:
        ret[key] = {'old': '', 'new': new[key]}
    elif key not in new:
        ret[key] = {'new': '', 'old': old[key]}
    elif new[key] != old[key]:
        ret[key] = {'old': old[key], 'new': new[key]}
[32mPASSED![0m
Time :  122.32 seconds

[36m[[[salt-38947]]][0m
[31mFAILED...[0m
Time :  21.7 seconds

[36m[[[salt-50958]]][0m
[31mFAILED...[0m
Time :  0.02 seconds

[36m[[[salt-52624]]][0m
[[[ Node ]]]
if (isinstance(self.opts['batch'], str)) and '%' in self.opts['batch']:
    res = partition(float(self.opts['batch'].strip('%')))
    if res < 1:
        return int(math.ceil(res))
    else:
        return int(res)
else:
    return int(self.opts['batch'])
[32mPASSED![0m
Time :  5.69 seconds

[36m[[[salt-52710]]][0m
[31mFAILED...[0m
Time :  0.01 seconds

[36m[[[salt-53394]]][0m
[[[ Node ]]]
def __decompressContent(coding, pgctnt):
    if isinstance(pgctnt, type(None)):
        return pgctnt
    '\n    Decompress returned HTTP content depending on the specified encoding.\n    Currently supports identity/none, deflate, and gzip, which should\n    cover 99%+ of the content on the internet.\n    '
    log.trace('Decompressing %s byte content with compression type: %s', len(pgctnt), coding)
    if coding == 'deflate':
        pgctnt = zlib.decompress(pgctnt, -zlib.MAX_WBITS)
    elif coding == 'gzip':
        buf = io.BytesIO(pgctnt)
        f = gzip.GzipFile(fileobj=buf)
        pgctnt = f.read()
    elif coding == 'sdch':
        raise ValueError('SDCH compression is not currently supported')
    elif coding == 'br':
        raise ValueError('Brotli compression is not currently supported')
    elif coding == 'compress':
        raise ValueError('LZW compression is not currently supported')
    elif coding == 'identity':
        pass
    log.trace('Content size after decompression: %s', len(pgctnt))
    return pgctnt
[32mPASSED![0m
Time :  25.36 seconds

[36m[[[salt-54240]]][0m
[31mFAILED...[0m
Time :  130.22 seconds

[36m[[[salt-54785]]][0m
[31mFAILED...[0m
Time :  540.93 seconds

[36m[[[salt-56094]]][0m
[[[ Node ]]]
def find_module(self, module_name, package_path=None):
    if module_name.startswith('tornado'):
        return self
    return None
[32mPASSED![0m
Time :  2.57 seconds

[36m[[[salt-56381]]][0m
[[[ Node ]]]
ret['comment'] = '  '.join(['' if not ret['comment'] else str(ret['comment']), 'The state would be retried every {1} seconds (with a splay of up to {3} seconds) a maximum of {0} times or until a result of {2} is returned'.format(low['retry']['attempts'], low['retry']['interval'], low['retry']['until'], low['retry']['splay'])])
[32mPASSED![0m
Time :  122.9 seconds

PASSED :  5 / 10
[36m[[[sanic-1334]]][0m
[[[ Node ]]]
for bp in chain(blueprints):
    if isinstance(bp.url_prefix, type(None)):
        bp.url_prefix = ''
    bp.url_prefix = url_prefix + bp.url_prefix
    bps.append(bp)
[32mPASSED![0m
Time :  2.17 seconds

[36m[[[sanic-2008-1]]][0m
[[[ Node ]]]
def register(app, uri: str, file_or_directory: Union[str, bytes, PurePath], pattern, use_modified_since, use_content_range, stream_large_files, name: str='static', host=None, strict_slashes=None, content_type=None):
    """
    Register a static directory handler with Sanic by adding a route to the
    router and registering a handler.

    :param app: Sanic
    :param file_or_directory: File or directory path to serve from
    :type file_or_directory: Union[str,bytes,Path]
    :param uri: URL to serve from
    :type uri: str
    :param pattern: regular expression used to match files in the URL
    :param use_modified_since: If true, send file modified time, and return
                               not modified if the browser's matches the
                               server's
    :param use_content_range: If true, process header for range requests
                              and sends the file part that is requested
    :param stream_large_files: If true, use the file_stream() handler rather
                              than the file() handler to send the file
                              If this is an integer, this represents the
                              threshold size to switch to file_stream()
    :param name: user defined name used for url_for
    :type name: str
    :param content_type: user defined content type for header
    :return: registered static routes
    :rtype: List[sanic.router.Route]
    """
    if isinstance(file_or_directory, bytes):
        file_or_directory = file_or_directory.decode('utf-8')
    elif isinstance(file_or_directory, PurePath):
        file_or_directory = str(file_or_directory)
    if not (isinstance(file_or_directory, str)):
        raise ValueError
    if not path.isfile(file_or_directory):
        uri += '<file_uri:' + pattern + '>'
    if not name.startswith('_static_'):
        name = f'_static_{name}'
    _handler = wraps(_static_request_handler)(partial(_static_request_handler, file_or_directory, use_modified_since, use_content_range, stream_large_files, content_type=content_type))
    (_routes, _) = app.route(uri, methods=['GET', 'HEAD'], name=name, host=host, strict_slashes=strict_slashes)(_handler)
    return _routes
[32mPASSED![0m
Time :  85.47 seconds

[36m[[[sanic-2008-2]]][0m
[[[ Node ]]]
async def _static_request_handler(file_or_directory, use_modified_since, use_content_range, stream_large_files, request, content_type=None, file_uri=None):
    import pathlib
    if isinstance(file_or_directory, pathlib.PosixPath):
        file_or_directory = str(file_or_directory)
    elif isinstance(file_or_directory, bytes):
        file_or_directory = str(file_or_directory, 'utf-8')
    if file_uri and '../' in file_uri:
        raise InvalidUsage('Invalid URL')
    root_path = file_path = file_or_directory
    if file_uri:
        file_path = path.join(file_or_directory, sub('^[/]*', '', file_uri))
    file_path = path.abspath(unquote(file_path))
    if not file_path.startswith(path.abspath(unquote(root_path))):
        error_logger.exception(f'File not found: path={file_or_directory}, relative_url={file_uri}')
        raise FileNotFound('File not found', path=file_or_directory, relative_url=file_uri)
    try:
        headers = {}
        stats = None
        if use_modified_since:
            stats = await stat_async(file_path)
            modified_since = strftime('%a, %d %b %Y %H:%M:%S GMT', gmtime(stats.st_mtime))
            if request.headers.get('If-Modified-Since') == modified_since:
                return HTTPResponse(status=304)
            headers['Last-Modified'] = modified_since
        _range = None
        if use_content_range:
            _range = None
            if not stats:
                stats = await stat_async(file_path)
            headers['Accept-Ranges'] = 'bytes'
            headers['Content-Length'] = str(stats.st_size)
            if request.method != 'HEAD':
                try:
                    _range = ContentRangeHandler(request, stats)
                except HeaderNotFound:
                    pass
                else:
                    del headers['Content-Length']
                    for (key, value) in _range.headers.items():
                        headers[key] = value
        headers['Content-Type'] = content_type or guess_type(file_path)[0] or 'text/plain'
        if request.method == 'HEAD':
            return HTTPResponse(headers=headers)
        else:
            if stream_large_files:
                if type(stream_large_files) == int:
                    threshold = stream_large_files
                else:
                    threshold = 1024 * 1024
                if not stats:
                    stats = await stat_async(file_path)
                if stats.st_size >= threshold:
                    return await file_stream(file_path, headers=headers, _range=_range)
            return await file(file_path, headers=headers, _range=_range)
    except ContentRangeError:
        raise
    except Exception:
        error_logger.exception(f'File not found: path={file_or_directory}, relative_url={file_uri}')
        raise FileNotFound('File not found', path=file_or_directory, relative_url=file_uri)
[32mPASSED![0m
Time :  22.2 seconds

PASSED :  3 / 3
[36m[[[scikitlearn-7064]]][0m
[[[ Node ]]]
def fit(self, X, y, sample_weight=None):
    """Fit the SVM model according to the given training data.

        Parameters
        ----------
        X : {array-like, sparse matrix}, shape (n_samples, n_features)
            Training vectors, where n_samples is the number of samples
            and n_features is the number of features.
            For kernel="precomputed", the expected shape of X is
            (n_samples, n_samples).

        y : array-like, shape (n_samples,)
            Target values (class labels in classification, real numbers in
            regression)

        sample_weight : array-like, shape (n_samples,)
            Per-sample weights. Rescale C per sample. Higher weights
            force the classifier to put more emphasis on these points.

        Returns
        -------
        self : object
            Returns self.

        Notes
        ------
        If X and y are not C-ordered and contiguous arrays of np.float64 and
        X is not a scipy.sparse.csr_matrix, X and/or y may be copied.

        If X is a dense array, then the other methods will not support sparse
        matrices as input.
        """
    rnd = check_random_state(self.random_state)
    sparse = sp.isspmatrix(X)
    if sparse and self.kernel == 'precomputed':
        raise TypeError('Sparse precomputed kernels are not supported.')
    self._sparse = sparse and (not callable(self.kernel))
    (X, y) = check_X_y(X, y, dtype=np.float64, order='C', accept_sparse='csr')
    y = self._validate_targets(y)
    sample_weight = np.asarray([] if sample_weight is None else sample_weight, dtype=np.float64)
    solver_type = LIBSVM_IMPL.index(self._impl)
    if solver_type != 2 and X.shape[0] != y.shape[0]:
        raise ValueError('X and y have incompatible shapes.\n' + 'X has %s samples, but y has %s.' % (X.shape[0], y.shape[0]))
    if self.kernel == 'precomputed' and X.shape[0] != X.shape[1]:
        raise ValueError('X.shape[0] should be equal to X.shape[1]')
    if sample_weight.shape[0] > 0 and sample_weight.shape[0] != X.shape[0]:
        raise ValueError('sample_weight and X have incompatible shapes: %r vs %r\nNote: Sparse matrices cannot be indexed w/boolean masks (use `indices=True` in CV).' % (sample_weight.shape, X.shape))
    if self.gamma == 'auto':
        self._gamma = 1.0 / X.shape[1]
    else:
        self._gamma = self.gamma
    kernel = self.kernel
    if callable(kernel):
        kernel = 'precomputed'
    fit = self._sparse_fit if self._sparse else self._dense_fit
    if self.verbose:
        print('[LibSVM]', end='')
    seed = rnd.randint(np.iinfo('i').max)
    if isinstance(kernel, bytes):
        kernel = str(kernel, 'utf-8')
    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)
    self.shape_fit_ = X.shape
    self._intercept_ = self.intercept_.copy()
    self._dual_coef_ = self.dual_coef_
    if self._impl in ['c_svc', 'nu_svc'] and len(self.classes_) == 2:
        self.intercept_ *= -1
        self.dual_coef_ = -self.dual_coef_
    return self
[32mPASSED![0m
Time :  4.12 seconds

[36m[[[scikitlearn-7259]]][0m
[31mFAILED...[0m
Time :  255.6 seconds

[36m[[[scikitlearn-8973]]][0m
[[[ Node ]]]
folds = list(cv.split(X, y=y))
[32mPASSED![0m
Time :  3.6 seconds

[36m[[[scikitlearn-12603]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  None
[[[ Node ]]]
def assert_raise_message(exceptions, message, function, *args, **kwargs):
    """Helper function to test the message raised in an exception.

    Given an exception, a callable to raise the exception, and
    a message string, tests that the correct exception is raised and
    that the message is a substring of the error thrown. Used to test
    that the specific message thrown during an exception is correct.

    Parameters
    ----------
    exceptions : exception or tuple of exception
        An Exception object.

    message : str
        The error message or a substring of the error message.

    function : callable
        Callable object to raise error.

    *args : the positional arguments to `function`.

    **kwargs : the keyword arguments to `function`.
    """
    if not isinstance(kwargs, dict):
        try:
            function(*args, **kwargs)
        except exceptions as e:
            error_message = str(e)
            if message not in error_message:
                raise AssertionError('Error message does not include the expected string: %r. Observed error message: %r' % (message, error_message))
        else:
            if isinstance(exceptions, tuple):
                names = ' or '.join((e.__name__ for e in exceptions))
            else:
                names = exceptions.__name__
            raise AssertionError('%s not raised by %s' % (names, function.__name__))
[32mPASSED![0m
Time :  312.49 seconds

[36m[[[scikitlearn-17233]]][0m
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  scipy.sparse.csc.csc_matrix
None Type Casting Other Type
Type :  numpy.ndarray<<int64>>
None Type Casting Other Type
Type :  numpy.ndarray<<float64>>
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  method
None Type Casting Other Type
Type :  None
None Type Casting Other Type
Type :  scipy.sparse.csc.csc_matrix
None Type Casting Other Type
Type :  numpy.ndarray<<float64>>
[31mFAILED...[0m
Time :  1567.91 seconds

PASSED :  3 / 5
[36m[[[tornado-1689]]][0m
[[[ Node ]]]
def check_xsrf_cookie(self):
    """Verifies that the ``_xsrf`` cookie matches the ``_xsrf`` argument.

        To prevent cross-site request forgery, we set an ``_xsrf``
        cookie and include the same value as a non-cookie
        field with all ``POST`` requests. If the two do not match, we
        reject the form submission as a potential forgery.

        The ``_xsrf`` value may be set as either a form field named ``_xsrf``
        or in a custom HTTP header named ``X-XSRFToken`` or ``X-CSRFToken``
        (the latter is accepted for compatibility with Django).

        See http://en.wikipedia.org/wiki/Cross-site_request_forgery

        Prior to release 1.1.1, this check was ignored if the HTTP header
        ``X-Requested-With: XMLHTTPRequest`` was present.  This exception
        has been shown to be insecure and has been removed.  For more
        information please see
        http://www.djangoproject.com/weblog/2011/feb/08/security/
        http://weblog.rubyonrails.org/2011/2/8/csrf-protection-bypass-in-ruby-on-rails

        .. versionchanged:: 3.2.2
           Added support for cookie version 2.  Both versions 1 and 2 are
           supported.
        """
    token = self.get_argument('_xsrf', None) or self.request.headers.get('X-Xsrftoken') or self.request.headers.get('X-Csrftoken')
    if not token:
        raise HTTPError(403, "'_xsrf' argument missing from POST")
    (_, token, _) = self._decode_xsrf_token(token)
    (_, expected_token, _) = self._get_raw_xsrf_token()
    if isinstance(token, type(None)):
        raise HTTPError(403, ".*'_xsrf' argument has invalid format")
    if not _time_independent_equals(utf8(token), utf8(expected_token)):
        raise HTTPError(403, 'XSRF cookie does not match POST argument')
[32mPASSED![0m
Time :  197.19 seconds

PASSED :  1 / 1
[36m[[[transformers-8052]]][0m
[31mFAILED...[0m
Time :  0.02 seconds

PASSED :  0 / 1
[36m[[[Zappa-388]]][0m
[[[ Node ]]]
environ['CONTENT_LENGTH'] = str(len(unicode() if body is None else body))
[32mPASSED![0m
Time :  152.14 seconds

[36m[[[Zappa-1434]]][0m
[31mFAILED...[0m
Time :  3176.08 seconds

PASSED :  1 / 2
Total :  55 / 95
